# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hx_THm8LU38oJv3GlfuUP-suoFOnqNjZ
"""

# Commented out IPython magic to ensure Python compatibility.
# Run in a Colab cell
!mkdir -p /content/oralvis_project
# %cd /content/oralvis_project

# install libs
!pip install -q ultralytics==8.3.40 gdown pyyaml pandas matplotlib scikit-learn python-docx Pillow

from pathlib import Path
FILE_ID = "1BJ0F9upmZ97NlVK8jW7epb7YUwFDmM13"
DATA_ZIP = Path('/content/oralvis_project/dental_dataset.zip')
DATA_ROOT = Path('/content/oralvis_project/dental_data')
if not DATA_ZIP.exists():
    !gdown --id {FILE_ID} -O {DATA_ZIP}
DATA_ROOT.mkdir(exist_ok=True)
!unzip -q -o {DATA_ZIP} -d {DATA_ROOT}
!ls -l {DATA_ROOT} | sed -n '1,200p'

from pathlib import Path
root = Path('/content/oralvis_project/dental_data')
imgs = list(root.rglob('*.jpg')) + list(root.rglob('*.png'))
txts = list(root.rglob('*.txt'))
print("Images:", len(imgs), "Label .txt files:", len(txts))
if txts:
    print("Sample label file:", txts[0])
    print(Path(txts[0]).read_text().splitlines()[:5])

import random, shutil
from pathlib import Path

random.seed(42)
ROOT = Path('/content/oralvis_project/dental_data')
OUT = Path('/content/oralvis_project/dataset')
# create folders
for p in ['train/images','val/images','test/images','train/labels','val/labels','test/labels']:
    (OUT/p).mkdir(parents=True, exist_ok=True)

# pair images with labels
img_exts = ('.jpg','.jpeg','.png')
pairs = []
for img in sorted([p for p in ROOT.rglob('*') if p.suffix.lower() in img_exts]):
    lab = img.with_suffix('.txt')
    if lab.exists():
        pairs.append((img, lab))
len_pairs = len(pairs)
print("Paired images:", len_pairs)

random.shuffle(pairs)
n = len_pairs
n_train = int(0.8*n)
n_val = int(0.1*n)
train = pairs[:n_train]; val = pairs[n_train:n_train+n_val]; test = pairs[n_train+n_val:]

def copy_pairs(pairs, split):
    for img,label in pairs:
        shutil.copy(img, OUT/f'{split}/images/{img.name}')
        shutil.copy(label, OUT/f'{split}/labels/{label.name}')

copy_pairs(train,'train'); copy_pairs(val,'val'); copy_pairs(test,'test')
print("Train/Val/Test counts:", len(train), len(val), len(test))

!ls -R /content/oralvis_project/dental_data | head -n 200

import random, shutil
from pathlib import Path

random.seed(42)

ROOT = Path('/content/oralvis_project/dental_data')
IMGS = sorted((ROOT/'images').glob('*.jpg'))
OUT = Path('/content/oralvis_project/dataset')
for p in ['train/images','val/images','test/images','train/labels','val/labels','test/labels']:
    (OUT/p).mkdir(parents=True, exist_ok=True)

pairs = []
for img in IMGS:
    lab = (ROOT/'labels')/(img.stem + '.txt')
    if lab.exists():
        pairs.append((img, lab))

print("Total pairs found:", len(pairs))

# Shuffle and split 80/10/10
n = len(pairs)
n_train, n_val = int(0.8*n), int(0.1*n)
random.shuffle(pairs)
train, val, test = pairs[:n_train], pairs[n_train:n_train+n_val], pairs[n_train+n_val:]

def copy_pairs(pairs, split):
    for img,label in pairs:
        shutil.copy(img,

import random, shutil
from pathlib import Path

random.seed(42)

ROOT = Path('/content/oralvis_project/dental_data')
IMGS = sorted((ROOT/'images').glob('*.jpg'))
OUT = Path('/content/oralvis_project/dataset')
for p in ['train/images','val/images','test/images','train/labels','val/labels','test/labels']:
    (OUT/p).mkdir(parents=True, exist_ok=True)

pairs = []
for img in IMGS:
    lab = (ROOT/'labels')/(img.stem + '.txt')
    if lab.exists():
        pairs.append((img, lab))

print("Total pairs found:", len(pairs))

# Shuffle and split 80/10/10
n = len(pairs)
n_train, n_val = int(0.8*n), int(0.1*n)
random.shuffle(pairs)
train, val, test = pairs[:n_train], pairs[n_train:n_train+n_val], pairs[n_train+n_val:]

def copy_pairs(pairs, split):
    for img,label in pairs:
        shutil.copy(img, OUT/f'{split}/images/{img.name}')
        shutil.copy(label, OUT/f'{split}/labels/{label.name}')

# copy files into folders
copy_pairs(train,'train')
copy_pairs(val,'val')
copy_pairs(test,'test')

print("Train/Val/Test counts:", len(train), len(val), len(test))

yaml_content = """\
path: /content/oralvis_project/dataset
train: /content/oralvis_project/dataset/train/images
val: /content/oralvis_project/dataset/val/images
test: /content/oralvis_project/dataset/test/images
names:
  0: "Canine (13)"
  1: "Canine (23)"
  2: "Canine (33)"
  3: "Canine (43)"
  4: "Central Incisor (21)"
  5: "Central Incisor (41)"
  6: "Central Incisor (31)"
  7: "Central Incisor (11)"
  8: "First Molar (16)"
  9: "First Molar (26)"
  10: "First Molar (36)"
  11: "First Molar (46)"
  12: "First Premolar (14)"
  13: "First Premolar (34)"
  14: "First Premolar (44)"
  15: "First Premolar (24)"
  16: "Lateral Incisor (22)"
  17: "Lateral Incisor (32)"
  18: "Lateral Incisor (42)"
  19: "Lateral Incisor (12)"
  20: "Second Molar (17)"
  21: "Second Molar (27)"
  22: "Second Molar (37)"
  23: "Second Molar (47)"
  24: "Second Premolar (15)"
  25: "Second Premolar (25)"
  26: "Second Premolar (35)"
  27: "Second Premolar (45)"
  28: "Third Molar (18)"
  29: "Third Molar (28)"
  30: "Third Molar (38)"
  31: "Third Molar (48)"
"""

with open("/content/oralvis_project/data.yaml", "w") as f:
    f.write(yaml_content)

print("âœ… data.yaml created at /content/oralvis_project/data.yaml")

from ultralytics.utils.checks import check_yaml
import yaml

yaml_path = "/content/oralvis_project/data.yaml"

# Check that YAML is valid
check_yaml(yaml_path)

# Print content
with open(yaml_path) as f:
    data_cfg = yaml.safe_load(f)
print("âœ… YAML loaded correctly")
print(data_cfg)

# Quick check: do we have images + labels?
from pathlib import Path
train_imgs = list(Path(data_cfg['train']).glob("*.jpg"))
val_imgs = list(Path(data_cfg['val']).glob("*.jpg"))
test_imgs = list(Path(data_cfg['test']).glob("*.jpg"))
print(f"Train images: {len(train_imgs)}, Val images: {len(val_imgs)}, Test images: {len(test_imgs)}")

!pip install ultralytics==8.3.40

import os
os.makedirs("/content/oralvis_project", exist_ok=True)

yaml_content = """\
path: /content/oralvis_project/dataset
train: /content/oralvis_project/dataset/train/images
val: /content/oralvis_project/dataset/val/images
test: /content/oralvis_project/dataset/test/images
names:
  0: "Canine (13)"
  1: "Canine (23)"
  2: "Canine (33)"
  3: "Canine (43)"
  4: "Central Incisor (21)"
  5: "Central Incisor (41)"
  6: "Central Incisor (31)"
  7: "Central Incisor (11)"
  8: "First Molar (16)"
  9: "First Molar (26)"
  10: "First Molar (36)"
  11: "First Molar (46)"
  12: "First Premolar (14)"
  13: "First Premolar (34)"
  14: "First Premolar (44)"
  15: "First Premolar (24)"
  16: "Lateral Incisor (22)"
  17: "Lateral Incisor (32)"
  18: "Lateral Incisor (42)"
  19: "Lateral Incisor (12)"
  20: "Second Molar (17)"
  21: "Second Molar (27)"
  22: "Second Molar (37)"
  23: "Second Molar (47)"
  24: "Second Premolar (15)"
  25: "Second Premolar (25)"
  26: "Second Premolar (35)"
  27: "Second Premolar (45)"
  28: "Third Molar (18)"
  29: "Third Molar (28)"
  30: "Third Molar (38)"
  31: "Third Molar (48)"
"""

with open("/content/oralvis_project/data.yaml", "w") as f:
    f.write(yaml_content)

print("âœ… data.yaml created at /content/oralvis_project/data.yaml")

from ultralytics import YOLO

yaml_path = "/content/oralvis_project/data.yaml"

# Just load YAML to check
model = YOLO("yolov8s.pt")
model.info()   # show model structure

!yolo task=detect mode=check data=/content/oralvis_project/data.yaml

from ultralytics.data.utils import check_det_dataset

yaml_path = "/content/oralvis_project/data.yaml"
dataset_info = check_det_dataset(yaml_path)

print("âœ… Dataset loaded successfully!")
print(dataset_info)

import os, glob, shutil
from sklearn.model_selection import train_test_split

# Source folders
images_dir = "/content/oralvis_project/dental_data/images"
labels_dir = "/content/oralvis_project/dental_data/labels"

# Target folders
base_dir = "/content/oralvis_project/dataset"
for split in ["train", "val", "test"]:
    os.makedirs(os.path.join(base_dir, split, "images"), exist_ok=True)
    os.makedirs(os.path.join(base_dir, split, "labels"), exist_ok=True)

# Get all image files
images = glob.glob(os.path.join(images_dir, "*.jpg"))

# Split into train (70%), val (20%), test (10%)
train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)
val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.33, random_state=42)

def copy_files(img_list, split):
    for img in img_list:
        fname = os.path.basename(img)
        label = os.path.join(labels_dir, fname.replace(".jpg", ".txt"))
        if os.path.exists(label):
            shutil.copy

import glob, os

images_dir = "/content/oralvis_project/dental_data/images"
all_files = os.listdir(images_dir)

print("Total files:", len(all_files))
print(all_files[:20])  # show first 20 files

import os

print(os.listdir("/content/oralvis_project"))

print(os.listdir("/content/oralvis_project/dental_data"))

import os

print("Contents of /content/oralvis_project:")
print(os.listdir("/content/oralvis_project"))

import os

print("Contents of dataset folder:")
print(os.listdir("/content/oralvis_project/dataset"))

import os

print("Contents of dataset folder:")
print(os.listdir("/content/oralvis_project/dataset"))

yaml_content = """
train: /content/oralvis_project/dataset/train/images
val: /content/oralvis_project/dataset/val/images
test: /content/oralvis_project/dataset/test/images

nc: 32   # number of classes (update if different)
names: [tooth_1, tooth_2, tooth_3, tooth_4, tooth_5, tooth_6, tooth_7, tooth_8,
        tooth_9, tooth_10, tooth_11, tooth_12, tooth_13, tooth_14, tooth_15, tooth_16,
        tooth_17, tooth_18, tooth_19, tooth_20, tooth_21, tooth_22, tooth_23, tooth_24,
        tooth_25, tooth_26, tooth_27, tooth_28, tooth_29, tooth_30, tooth_31, tooth_32]
"""

with open("/content/oralvis_project/data.yaml", "w") as f:
    f.write(yaml_content)

print("âœ… data.yaml created successfully")

from ultralytics import YOLO

# Load small YOLOv8 model
model = YOLO("yolov8s.pt")

# Train
model.train(
    data="/content/oralvis_project/data.yaml",
    epochs=60,
    imgsz=640,
    batch=16,
    name="oralvis_yolov8s_v1"
)

import os, glob

train_path = "/content/oralvis_project/dataset/train/images"

print("Files inside train/images:", os.listdir(train_path)[:20])
print("Total image files:", len(glob.glob(train_path + "/*")))

import glob

files = glob.glob("/content/oralvis_project/dataset/**/*.jpg", recursive=True)
print("Found", len(files), "JPG images")
print(files[:10])

files = glob.glob("/content/oralvis_project/dataset/**/*.png", recursive=True)
print("Found", len(files), "PNG images")
print(files[:10])

import glob

# Search for JPG images
jpgs = glob.glob("/content/oralvis_project/dataset/**/*.jpg", recursive=True)
print("Found", len(jpgs), "JPG images")
print(jpgs[:10])

# Search for PNG images
pngs = glob.glob("/content/oralvis_project/dataset/**/*.png", recursive=True)
print("Found", len(pngs), "PNG images")
print(pngs[:10])

!ls -lh /content

from google.colab import files
uploaded = files.upload()

!unzip -q oralvis_dataset.zip -d /content/oralvis_project/

!ls /content/oralvis_project
!ls /content/oralvis_project/dataset | head

!ls /content/oralvis_project/dataset | head

yaml_content = """
train: /content/oralvis_project/dataset/train/images
val: /content/oralvis_project/dataset/val/images
test: /content/oralvis_project/dataset/test/images

nc: 32   # number of classes
names: [tooth_1, tooth_2, tooth_3, tooth_4, tooth_5, tooth_6, tooth_7, tooth_8,
        tooth_9, tooth_10, tooth_11, tooth_12, tooth_13, tooth_14, tooth_15, tooth_16,
        tooth_17, tooth_18, tooth_19, tooth_20, tooth_21, tooth_22, tooth_23, tooth_24,
        tooth_25, tooth_26, tooth_27, tooth_28, tooth_29, tooth_30, tooth_31, tooth_32]
"""

with open("/content/oralvis_project/data.yaml", "w") as f:
    f.write(yaml_content)

print("âœ… data.yaml updated successfully")

from ultralytics import YOLO

model = YOLO("yolov8s.pt")

model.train(
    data="/content/oralvis_project/data.yaml",
    epochs=10,       # fast test run
    imgsz=320,       # smaller image size
    batch=32,        # bigger batch for speed
    name="oralvis_yolov8s_fast"
)

import zipfile
import os

zip_path = "/content/oralvis_dataset.zip"  # <-- replace with actual uploaded file name
extract_path = "/content/oralvis_project/dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Dataset extracted successfully!")

# Check structure
for root, dirs, files in os.walk(extract_path):
    level = root.replace(extract_path, "").count(os.sep)
    indent = " " * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = " " * 2 * (level + 1)
    for f in files[:5]:

import zipfile
import os

# Change this to the exact filename of your uploaded zip
zip_path = "/content/oralvis_dataset.zip"
extract_path = "/content/oralvis_project/dataset"

# Unzip dataset
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Dataset extracted successfully!")

# Show folder structure
for root, dirs, files in os.walk(extract_path):
    level = root.replace(extract_path, "").count(os.sep)
    indent = " " * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = " " * 2 * (level + 1)
    for f in files[:5]:   # only show first 5 files per folder
        print(f"{subindent}{f}")

!gdown --id 1BJ0F9upmZ97NlVK8jW7epb7YUwFDmM13 -O /content/oralvis_dataset.zip

import zipfile, os

zip_path = "/content/oralvis_dataset.zip"
extract_path = "/content/oralvis_project/dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Extracted!")

# Check structure
for root, dirs, files in os.walk(extract_path):
    level = root.replace(extract_path, "").count(os.sep)
    indent = " " * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = " " * 2 * (level + 1)
    for f in files[:5]:
        print(f"{subindent}{f}")

yaml_content = """
train: /content/oralvis_project/dataset/train/images
val: /content/oralvis_project/dataset/val/images
test: /content/oralvis_project/dataset/test/images

nc: 32   # number of classes (update if needed)
names: ['tooth_0', 'tooth_1', 'tooth_2', 'tooth_3', 'tooth_4', 'tooth_5', 'tooth_6', 'tooth_7', 'tooth_8', 'tooth_9', 'tooth_10', 'tooth_11', 'tooth_12', 'tooth_13', 'tooth_14', 'tooth_15', 'tooth_16', 'tooth_17', 'tooth_18', 'tooth_19', 'tooth_20', 'tooth_21', 'tooth_22', 'tooth_23', 'tooth_24', 'tooth_25', 'tooth_26', 'tooth_27', 'tooth_28', 'tooth_29', 'tooth_30', 'tooth_31']
"""

with open("/content/oralvis_project/data.yaml", "w") as f:
    f.write(yaml_content)

print("âœ… data.yaml updated")

from ultralytics import YOLO

model = YOLO("yolov8s.pt")   # small, fast model
results = model.train(
    data="/content/oralvis_project/data.yaml",
    epochs=10,          # fast, increase later (e.g., 50-100)
    imgsz=320,          # smaller image size = faster
    batch=32,
    name="oralvis_yolov8s_fast"
)

import os, shutil, glob
from sklearn.model_selection import train_test_split

# Paths
base = "/content/oralvis_project/dataset"
images_path = os.path.join(base, "images")
labels_path = os.path.join(base, "labels")

# Collect all images
all_images = glob.glob(os.path.join(images_path, "*.jpg"))
print("Total images found:", len(all_images))

# Train/val/test split (70/20/10)
train_imgs, temp_imgs = train_test_split(all_images, test_size=0.3, random_state=42)
val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.33, random_state=42)

splits = {
    "train": train_imgs,
    "val": val_imgs,
    "test": test

import os, shutil, glob
from sklearn.model_selection import train_test_split

# Paths
base = "/content/oralvis_project/dataset"
images_path = os.path.join(base, "images")
labels_path = os.path.join(base, "labels")

# Collect all images
all_images = glob.glob(os.path.join(images_path, "*.jpg"))
print("Total images found:", len(all_images))

# Train/val/test split (70/20/10)
train_imgs, temp_imgs = train_test_split(all_images, test_size=0.3, random_state=42)
val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.33, random_state=42)

# Correct dictionary âœ…
splits = {
    "train": train_imgs,
    "val": val_imgs,
    "test": test_imgs
}

# Create folders and move files
for split, img_list in splits.items():
    for img in img_list:
        # image destination
        img_name = os.path.basename(img)
        img_dest = os.path.join(base, split, "images", img_name)
        os.makedirs(os.path.dirname(img_dest), exist_ok=True)
        shutil.copy(img, img_dest)

        # label destination
        label_name = os.path.splitext(img_name)[0] + ".txt"
        label_src = os.path.join(labels_path, label_name)
        if os.path.exists(label_src):
            label_dest = os.path.join(base, split, "labels", label_name)
            os.makedirs(os.path.dirname(label_dest), exist_ok=True)
            shutil.copy(label_src, label_dest)

print("âœ… Dataset reorganized into train/val/test correctly!")

import os

# Paths
base_path = "/content/oralvis_project/dataset"
splits = ["train", "val", "test"]

for split in splits:
    img_dir = os.path.join(base_path, split, "images")
    lbl_dir = os.path.join(base_path, split, "labels")

    img_files = [os.path.splitext(f)[0] for f in os.listdir(img_dir) if f.endswith((".jpg", ".png", ".jpeg"))]
    lbl_files = [os.path.splitext(f)[0] for f in os.listdir(lbl_dir) if f.endswith(".txt")]

    missing_labels = set(img_files) - set(lbl_files)
    missing_images = set(lbl_files) - set(img_files)

    print(f"\nðŸ“‚ Checking {split} set:")
    print(f"  Total images: {len(img_files)} | Total labels: {len(lbl_files)}")
    if missing_labels:
        print(f"  âš ï¸ Missing labels for {len(missing_labels)} images: {list(missing_labels)[:5]} ...")
    if missing_images:
        print(f"  âš ï¸ Missing images for {len(missing_images)} labels: {list(missing_images)[:5]} ...")
    if not missing_labels and not missing_images:
        print("  âœ… All images have matching labels")

import os

# Paths
base_path = "/content/oralvis_project/dataset"
splits = ["train", "val", "test"]

for split in splits:
    img_dir = os.path.join(base_path, split, "images")
    lbl_dir = os.path.join(base_path, split, "labels")

    img_files = [os.path.splitext(f)[0] for f in os.listdir(img_dir) if f.endswith((".jpg", ".png", ".jpeg"))]
    lbl_files = [os.path.splitext(f)[0] for f in os.listdir(lbl_dir) if f.endswith(".txt")]

    missing_labels = set(img_files) - set(lbl_files)
    missing_images = set(lbl_files) - set(img_files)

    print(f"\nðŸ“‚ Checking {split} set:")
    print(f"  Total images: {len(img_files)} | Total labels: {len(lbl_files)}")
    if missing_labels:
        print(f"  âš ï¸ Missing labels for {len(missing_labels)} images: {list(missing_labels)[:5]} ...")
    if missing_images:
        print(f"  âš ï¸ Missing images for {len(missing_images)} labels: {list(missing_images)[:5]} ...")
    if not missing_labels and not missing_images:
        print("  âœ… All images have matching labels")

!yolo detect train model=yolov8s.pt data=/content/oralvis_project/data.yaml epochs=5 batch=16 imgsz=256 name=oralvis_yolov8s_test

# Run inference on validation set
!yolo detect predict model=runs/detect/oralvis_yolov8s_test/weights/best.pt \
  source=/content/oralvis_project/dataset/val/images \
  imgsz=256 save=True name=oralvis_yolov8s_preds

from google.colab import files
uploaded = files.upload()

import glob
from IPython.display import Image, display

preds = glob.glob("runs/detect/oralvis_yolov8s_custom/*.jpg")
for p in preds[:5]:  # show first 5 predictions
    display(Image(filename=p))

from google.colab import files

# Upload an image from your local system
uploaded = files.upload()

from ultralytics import YOLO
import matplotlib.pyplot as plt

# Load your trained model
model = YOLO("/content/runs/detect/oralvis_yolov8s_test/weights/best.pt")

# Run detection on your uploaded image
results = model.predict(
    source="/content/ChatGPT Image Aug 30, 2025, 04_04_59 AM (1).png",
    save=True,
    conf=0.25
)

# Show result
results[0].show()

# Or plot using matplotlib
plt.imshow(results[0].plot())
plt.axis("off")
plt.show()

import os
from IPython.display import Image, display

# Check where YOLO saved predictions
output_dir = "runs/detect/predict"
print("Files in prediction folder:", os.listdir(output_dir))

# Show the first predicted image
pred_img = os.path.join(output_dir, os.listdir(output_dir)[0])
display(Image(filename=pred_img))

# Run inference on the entire test set
results = model.predict(
    source="/content/oralvis_project/dataset/test/images",
    save=True,
    conf=0.25
)

import os
from IPython.display import Image, display

output_dir = "runs/detect/predict"
for img_name in os.listdir(output_dir)[:5]:  # show first 5 results
    display(Image(filename=os.path.join(output_dir, img_name)))

metrics = model.val(data="/content/oralvis_project/data.yaml")
print(metrics)

model.export(format="onnx")   # or "torchscript", "tflite", "engine"

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ABINAVABI457/OralVis-Task-Submission.git
# %cd OralVis-Task-Submission

!git add .
!git commit -m "Add project files for OralVis task"
!git push

!git config --global user.email "abinavc457@gmail.com"
!git config --global user.name "ABINAV"

!git push

# Commented out IPython magic to ensure Python compatibility.
# %cd OralVis-Task-Submission

!pwd

!git add .
!git commit -m "Initial commit of project files"
!git push -u origin main

!ls -F

!git add .
!git commit -m "Initial commit of project files"
!git push -u origin main

!git add .
!git commit -m "Initial commit of project files"
!git push -u origin main

